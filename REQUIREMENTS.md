# use-ai High-Level Feature Requirements & Test Coverage

This document lists user-facing capabilities in requirements format with test coverage status.

**Legend:**
- âœ… TESTED - Feature has test coverage
- ğŸ†— OK - Not explicitly tested, but OK (implicitly tested or obvious by existence)
- âŒ NOT TESTED - Feature exists but lacks tests
- âš ï¸ PARTIAL - Feature has some test coverage but gaps remain

---

## Client Features

### Tool Definition & Registration

âœ… React components can expose tools (functions) to the AI using the useAI hook
âœ… Tools can be defined with type-safe parameters using Zod schemas
âœ… Tools can be defined without parameters
âœ… Tools can be marked as requiring confirmation before execution
âœ… Tool execution errors are caught and reported back to the AI
âœ… Tools are automatically registered when components mount and unregistered when they unmount
âœ… `useAI` can be enabled / disabled conditionally (e.g. for feature flags)
âœ… `UseAIProvder` can be enabled / disabled conditionally (e.g. for feature flags)

### Component State Management

âœ… Components can provide their current state to the AI via the prompt option
âœ… The system waits for React re-renders after tool execution to capture updated state before responding
âœ… Components can be marked as "invisible" to skip render waiting (for provider-type components)
âœ… Multiple instances of the same component can register separate tools using unique IDs
âœ… Tool names are automatically namespaced when component IDs are provided

### Chat & Conversation Management

âœ… Chat history is automatically persisted to localStorage by default
âœ… Users can create multiple chats and switch between them
âœ… Chat titles are auto-generated from the first user message
âœ… A maximum of 20 chats are stored by default, with oldest chats auto-deleted
âœ… Users can delete individual chats from the history
âœ… Chat messages persist across page reloads
âœ… Full conversation context is maintained when resuming chats
âœ… Messages support displayMode metadata for custom styling ('default' | 'error')
âœ… Error messages are visually distinguished with light red backgrounds and red text
âœ… Display modes are persisted with messages and restored on page reload
âœ… Custom chat storage backends can be implemented via the ChatRepository interface

### User Interface

âœ… A floating button provides access to the AI chat interface
âœ… The floating button indicates connection status (green when connected, gray when offline)
âœ… The floating button shows an unread indicator when new messages arrive
âœ… A chat panel displays conversation history with timestamps
âœ… The chat panel supports multi-line input with Shift+Enter for newlines
âœ… The chat panel shows a "Thinking..." indicator while the AI processes requests
âœ… Empty chat displays up to 4 randomly selected suggestions from all mounted components
âœ… Users can click suggestions to send them as messages
âŒ Custom UI components can replace the default floating button
âŒ Custom UI components can replace the default chat panel
âœ… The chat UI can be completely disabled by passing null to CustomButton and CustomChat props
âŒ AI responses can render Markdown.
ğŸ†— The UI can be themed.
âŒ The chat UI can be optionally embedded anywhere. (e.g. in a sidebar)
âŒ The user can upload files to be sent to the AI.
âŒ The user can save commands as slash /commands to recall again in future.

### Model Selection
âœ… The user can select an agent, if multiple agents are configured on the backend.

### Connection & Error Handling

âœ… The client automatically connects to the WebSocket server on initialization
âœ… The client automatically reconnects with exponential backoff on disconnect
âœ… Connection status is exposed to components via the useAI hook
âœ… The system prevents sending messages when disconnected
âœ… Error messages are displayed in the chat UI with distinctive red styling (light red bubble, red text)
âœ… Three error types are supported: API_OVERLOADED, RATE_LIMITED, UNKNOWN_ERROR
âœ… Default English error messages are provided for all error types
âœ… Custom error messages can be configured via the errorMessages prop on UseAIProvider
âœ… Error codes are defined in an exhaustive enum shared between server and client
âœ… Error messages persist across page reloads with displayMode metadata
âŒ Custom error handlers can be provided via the onError callback

### Context & System Prompts

âŒ A global system prompt can be configured to provide instructions to the AI
âŒ The useAIContext hook provides access to connection state and chat management functions
   NOTE: The hook exists and chat management functions are tested via chat-management.integration.test.tsx,
   but the hook itself is not directly tested

### Internationalization (i18n)
ğŸ†— All strings can be localized.

### MCP Integration (Client-Side)

âŒ Custom headers can be provided for MCP requests via the mcpHeadersProvider
âŒ The mcpHeadersProvider function is called on each AI invocation to get fresh headers
âŒ MCP header providers support exact URL matching and glob patterns
   NOTE: Client-side MCP feature exists in implementation but has no test coverage

### Build / Packaging Requirements
âŒ Developers can install a fully bundled version of the client library to avoid dependency conflicts.
âœ… React 16 -> 18 is supported.

---

## Server Features

### Core Architecture

âœ… The server coordinates communication between client applications and AI agents using WebSocket (Socket.IO)
âœ… The AG-UI protocol is used for communication between client and server
âœ… The server maintains separate sessions for each connected client
âœ… The server tracks conversation history and tool calls per session
âœ… The server exposes a /health endpoint for Kubernetes health checks

### Agent System

âœ… Multiple AI agents can be configured (Claude, OpenAI, Google, etc. via AI SDK)
âœ… The AISDKAgent integrates with any AI SDK language model
âœ… Agents automatically handle multi-step tool execution (up to 10 steps)
âœ… Custom agents can be implemented by implementing the Agent interface
âš ï¸ The system instructs the AI to ask for confirmation before calling confirmation-required tools

### Tool Execution Coordination

âœ… The AI can run MCP tools to do tasks in the frontend
âœ… The server coordinates tool calls between the AI and client
âœ… The server waits for tool results from the client before continuing
âœ… The server handles multiple sequential tool calls in a single conversation turn

### Rate Limiting

âœ… Rate limiting can be configured per IP address using a sliding window algorithm
âœ… The maximum number of requests per window can be configured via environment variables
âœ… The window duration can be configured via environment variables
âœ… Rate limiting can be disabled by setting max requests to 0
âœ… Different clients have independent rate limits
âœ… Rate limits reset after the time window expires
âœ… The system returns helpful error messages with retry-after information when rate limited

### MCP (Model Context Protocol) Integration

âœ… Remote MCP servers can be specified on the backend to provide additional tools
âœ… Each MCP endpoint specifies a URL, optional headers, optional namespace prefix, and timeout
âœ… MCP endpoints can be filtered using authorization provided by the use-ai client.
âœ… MCP tool names are prefixed with namespace to avoid conflicts
âœ… The server fetches MCP tool schemas on initialization using JSON-RPC 2.0
âœ… The server retries failed MCP endpoint initialization up to 3 times
âœ… MCP tools are executed via JSON-RPC 2.0 calls to the remote server
âœ… MCP tool execution has configurable timeout (default 30 seconds)
âš ï¸ Custom headers can be added to MCP requests (server-wide)
âš ï¸ Custom headers can be added to MCP requests (per-request)
âš ï¸ Per-request headers override server-wide configured headers
âœ… MCP header configuration supports exact URL matching and glob patterns
âœ… MCP tool schemas can be periodically refreshed when configured
âœ… MCP endpoints are cleaned up when the server shuts down

### Plugin Architecture

âš ï¸ The server supports plugins that extend functionality
âš ï¸ Plugins can register custom message handlers for new message types
âš ï¸ Plugins receive lifecycle hooks when clients connect and disconnect
âš ï¸ Plugins have access to the client session for state management

### Observability & Logging

âœ… Structured logging is available in JSON or pretty-printed format
âœ… Log format can be configured via LOG_FORMAT environment variable
âœ… The logger supports info, warn, error, and debug levels
âœ… The logger includes timestamps in all log entries
âœ… The logger redacts sensitive header values in MCP logs (unless DEBUG=1)
âœ… Langfuse observability can be enabled for LLM tracking and analytics
âœ… Langfuse integration tracks conversation sessions, tool calls, and token usage
âœ… Langfuse telemetry includes session metadata (sessionId, threadId, runId, ipAddress, toolCount)
âœ… Langfuse observability is automatically enabled when LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY are set

### Error Handling

âœ… The server emits RUN_ERROR events when agent execution fails
âœ… The server catches and handles AI SDK model errors
âœ… The server detects API overload errors (HTTP 529) and sends API_OVERLOADED error code
âœ… The server detects rate limiting errors (HTTP 429) and sends RATE_LIMITED error code
âœ… The server sends structured error codes using the ErrorCode enum (not raw error messages)
âœ… The server logs detailed error information including retry attempts for debugging
âœ… The server handles MCP tool execution errors and propagates them to the AI
âœ… The server emits helpful error messages when requested agents are not found
âŒ The server supports aborting in-flight agent executions via ABORT_RUN messages

### Configuration

âœ… The server port can be configured via PORT environment variable
âœ… The server can be initialized with multiple agents
âœ… API keys for different AI providers are read from environment variables
âœ… The server validates that at least one agent is configured on startup
âœ… MCP endpoint configuration can be provided via environment variables

---

## Workflow Features

### Workflow Execution

âœ… Headless workflows can be triggered via the `useAIWorkflow` hook
âœ… Workflows are stateless (no conversation history) unlike chat-based agents
âœ… Multiple workflow runners can be configured (e.g., Dify, Flowise)
âœ… Workflows execute via the WorkflowsPlugin on the server
âœ… Only one workflow can run at a time per useAIWorkflow hook instance
âœ… Workflow execution status is tracked (idle, running, completed, error)

### Dify Integration

âœ… Dify workflows can be integrated via the DifyWorkflowRunner
âœ… Dify API base URL is configurable
âœ… Workflow IDs map to Dify app API keys
âœ… The system sends requests to Dify's /workflows/run endpoint
âœ… The system handles Dify's Server-Sent Events (SSE) streaming responses
âœ… Text output from Dify workflows is streamed to the client in real-time
âœ… The system implements timeouts for Dify requests (100 seconds)
âœ… The system provides helpful error messages for Dify API failures (404, 401, 500)

### Workflow Lifecycle & Callbacks

âœ… Workflow inputs can be provided as arbitrary JSON data
âœ… Progress callbacks can track workflow execution (onProgress, onComplete, onError)
âœ… The onProgress callback is called with status updates and accumulated text
âœ… The onComplete callback is called with final results when workflow finishes
âœ… The onError callback is called with error details when workflow fails
âœ… Workflows emit AG-UI protocol events (RUN_STARTED, TEXT_MESSAGE_*, RUN_FINISHED, RUN_ERROR)

### Workflow Tool Integration

âœ… Workflows can call back to client-side tools defined with defineTool
      âš ï¸ **NOTE**: DifyWorkflowRunner does not implement tool callbacks yet.
âœ… Tools can be provided to workflows via the trigger options
âœ… Tool calls from workflows are tracked with names, arguments, and results
âœ… The onProgress callback receives updated tool call information after each execution
âœ… Tool execution errors are sent back to the workflow

---

## Protocol & Types

### AG-UI Protocol

âœ… The AG-UI protocol defines standardized event types for AI-UI communication
âœ… The protocol supports streaming text messages (TEXT_MESSAGE_START, _CONTENT, _END)
âœ… The protocol supports streaming tool calls (TOOL_CALL_START, _ARGS, _END)
âœ… The protocol supports run lifecycle events (RUN_STARTED, RUN_FINISHED, RUN_ERROR)
âœ… The protocol supports state snapshots (STATE_SNAPSHOT, MESSAGES_SNAPSHOT)
ğŸ†— The protocol supports thinking messages (THINKING_TEXT_MESSAGE_*, THINKING_START, THINKING_END)
   NOTE: Types are imported from @ag-ui/core but not implemented or tested in use-ai
ğŸ†— The protocol supports chunked messages (TEXT_MESSAGE_CHUNK, TOOL_CALL_CHUNK)
   NOTE: Types are imported from @ag-ui/core; TEXT_MESSAGE_CHUNK tested, TOOL_CALL_CHUNK untested
ğŸ†— The protocol supports activity tracking (ACTIVITY_SNAPSHOT, ACTIVITY_DELTA)
   NOTE: Types are imported from @ag-ui/core but not implemented or tested in use-ai
ğŸ†— The protocol supports step tracking (STEP_STARTED, STEP_FINISHED)
   NOTE: Types are imported from @ag-ui/core but not implemented or tested in use-ai
ğŸ†— The protocol supports raw and custom events (RAW, CUSTOM)
   NOTE: Types are imported from @ag-ui/core but not implemented or tested in use-ai
âœ… All events support optional timestamps

### Message Types

âœ… The protocol supports user, assistant, system, developer, and tool message roles
âœ… Tool messages include tool call ID and result content
âœ… Assistant messages can include tool calls
âœ… The protocol supports activity messages for tracking activities
âœ… The protocol supports binary content in messages (images, files, etc.)

### Type Safety & Exports

ğŸ†— The client exports TypeScript types for all hooks, components, and configurations
ğŸ†— The server exports TypeScript types for agents, plugins, and configurations
ğŸ†— The core package exports AG-UI protocol types
ğŸ†— Zod is re-exported from the client package for schema definitions